{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample\n",
    "\n",
    "A common problem is that the input format of different models is highly different, making it very difficult to load and utilize data. `Sample` solve this problem by decomposing various NLP task data into underlying `Fields`, which cover all basic input types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are built-in `Samples` of TextFlint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Task                            | Key                                              | Sample                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
    "|:---------------------------------|:--------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Aspect Level Sentiment Analysis | sentence, term_list                              | {\"sentence\": \"The bread is top notch as well.\",         \"term_list\": {             \"32897564#894393#2_0\":                 {\"id\": \"32897564#894393#2_0\",                  \"polarity\": \"positive\",                  \"term\": \"bread\",                  \"from\": 4,                  \"to\": 9,                  \"opinion_words\": [\"top notch\"],                  \"opinion_position\": [[13, 22]]}         }     }                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| Coreference Resolution          | sentences, clusters                              | {\"sentences\": [[\"News\", \"and\", \"events\", \"happen\", \"every\", \"day\", \".\"], [\"What\", \"you\", \"are\", \"interested\", \"in\", \"is\", \"exactly\", \"what\", \"our\", \"focuses\", \"are\", \".\"], [\"This\", \"is\", \"CCTV\", \"Focus\", \"Today\", \".\"], [\"Prior\", \"to\", \"the\", \"APEC\", \"meeting\", \",\", \"Japanese\", \"Prime\", \"Minister\", \"Junichiro\", \"Koizumi\", \"visited\", \"Yasukuni\", \"Shrine\", \"for\", \"the\", \"fifth\", \"time\", \"and\", \"was\", \"strongly\", \"condemned\", \"by\", \"Asian\", \"nations\", \"such\", \"as\", \"China\", \"and\", \"South\", \"Korea\", \".\"], [\"What\", \"kind\", \"of\", \"situation\", \"will\", \"Japan\", \"find\", \"itself\", \"in\", \"at\", \"the\", \"APEC\", \"summit\", \"?\"], [\"What\", \"heavy\", \"prices\", \"will\", \"Japan\", \"pay\", \"for\", \"Koizumi\", \"'s\", \"paying\", \"respect\", \"to\", \"the\", \"ghosts\", \"?\"], [\"Focus\", \"Today\", \"is\", \"coming\", \"up\", \"in\", \"a\", \"moment\", \".\"]], \"clusters\": [[[86, 87], [19, 19]], [[67, 69], [27, 29]], [[31, 35], [78, 79]], [[64, 64], [75, 75], [62, 62]]]}                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
    "| Chinese Word Segmentation       | x, y                                             | {\"x\": \"小明 好想 送 Jo 圣诞 礼物\", \"y\": []}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
    "| Dependency Parsing              | word, postag, head, deprel                       | {\"word\" : ['Influential', 'members', 'of', 'the', 'House', 'Ways', 'and',         'Means', 'Committee', 'introduced', 'legislation', 'that',         'would', 'restrict', 'how', 'the', 'new', 'savings-and-loan',         'bailout', 'agency', 'can', 'raise', 'capital', ',', 'creating',         'another', 'potential', 'obstacle', 'to', 'the', 'government',         \"'s\", 'sale', 'of', 'sick', 'thrifts', '.'], \"postag\": ['JJ', 'NNS', 'IN', 'DT', 'NNP', 'NNP', 'CC', 'NNP', 'NNP',           'VBD', 'NN', 'WDT', 'MD', 'VB', 'WRB', 'DT', 'JJ', 'JJ', 'NN',           'NN', 'MD', 'VB', 'NN', ',', 'VBG', 'DT', 'JJ', 'NN', 'TO',           'DT', 'NN', 'POS', 'NN', 'IN', 'JJ', 'NNS', '.'], \"head\": ['2', '10', '2', '6', '6', '3', '6', '9', '6', '0', '10', '14',         '14', '11', '22', '20', '20', '20', '20', '22', '22', '14', '22',         '14', '14', '28', '28', '25', '28', '31', '33', '31', '29', '33',         '36', '34', '10'], \"deprel\":  ['amod', 'nsubj', 'prep', 'det', 'nn', 'pobj', 'cc', 'nn',           'conj', 'root', 'dobj', 'nsubj', 'aux', 'rcmod', 'advmod',           'det', 'amod', 'amod', 'nn', 'nsubj', 'aux', 'ccomp', 'dobj',           'punct', 'xcomp', 'det', 'amod', 'dobj', 'prep', 'det', 'poss',           'possessive', 'pobj', 'prep', 'amod', 'pobj', 'punct']}                                                                                |\n",
    "| Machine Reading Comprehension   | context, question, answers, title, is_impossible | {\"context\":  \"Super Bowl 50 was an American football game to determine the champion ' \\           'of the National Football League ' \\           '(NFL) for the 2015 season. The American Football Conference (AFC)' \\           ' champion ' \\           'Denver Broncos defeated the National Football Conference (NFC) ' \\           'champion Carolina Panthers 24–10 ' \\           'to earn their third Super Bowl title. The game was played on ' \\           'February 7, 2016, at Levi\\'s Stadium ' \\           'in the San Francisco Bay Area at Santa Clara, California. As ' \\           'this was the 50th Super Bowl, ' \\           'the league emphasized the \"golden anniversary\" with various ' \\           'gold-themed initiatives, ' \\           'as well as temporarily suspending the tradition of naming each ' \\           'Super Bowl game with Roman numerals ' \\           '(under which the game would have been known as \"Super Bowl L\"), ' \\           'so that the logo could prominently feature the Arabic numerals 50.\", \"question\":  \"Which NFL team represented the AFC at Super Bowl 50?\" , \"answers\":  [{\"text\": \"Denver Broncos\",             \"answer_start\": 177},            {\"text\": \"Denver Broncos\",             \"answer_start\": 177},            {\"text\": \"Denver Broncos\",             \"answer_start\": 177}], \"title\":  \"Super_Bowl_50\", \"is_impossible\": False} |\n",
    "| Named Entity Recognition        | x, y                                             | {\"x\": ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British',               'lamb', '.'],         \"y\": ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
    "| Natural language inference      | hypothesis, premise                              | {\"hypothesis\": \"MR zhang has 10 students\",         \"premise\": \"Mr zhang has 20 students\",         \"y\": \"contradiction\"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| Part-of-Speech  Tagging         | x, y                                             | {\"x\": ['That', 'is', 'a', 'good', 'survey'],         \"y\": ['DT', 'VBZ', 'DT', 'JJ', 'NN']}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| Relation Extraction             | x, subj, obj, y                                  | {\"x\": [\"``\", \"The\", \"situation\", \"is\", \"very\", \"serious\", \",\", \"''\",               \"Mattis\", \",\", \"30\", \",\", \"told\", \"reporters\", \"after\",               \"meeting\", \"with\", \"Ban\", \"in\", \"New\", \"York\", \".\"],         \"subj\": [8, 8], \"obj\": [10, 10], \"y\": \"age\", 'sample_id': None}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
    "| Sentiment Analysis              | x, y                                             | {\"x\": \"Brilliant and moving performances by \"              \"Tom Courtenay and Peter Finch\",         \"y\": \"negative\"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
    "| Semantic Matching               | sentence1, sentence2, y                          | {\"sentence1\": \"MR zhang has 10 students\",         \"sentence2\": \"Mr zhang has 20 students\",         \"y\": \"0\"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take SASample as an example\n",
    "from textflint.input.component.sample.sa_sample import SASample\n",
    "\n",
    "data = {'x': 'Titanic is my favorite movie. The leading actor is good.','y': 'pos'}\n",
    "sample = SASample(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sample` provides common linguistic functions, including tokenization, partof-speech tagging and dependency parsing,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Titanic', 0, 1, 'PRODUCT')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.get_ner('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP', 'VBZ', 'PRP$', 'JJ', 'NN', '.', 'DT', 'VBG', 'NN', 'VBZ', 'JJ', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.get_pos('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `TextFlint` break down the arbitrary text transformation method into some atomic operations inside `Sample`, backed with clean and consistent implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Titanic is my favorite movie. The leading actor is good.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.get_text('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Titanic',\n",
       " 'is',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'movie',\n",
       " '.',\n",
       " 'The',\n",
       " 'leading',\n",
       " 'actor',\n",
       " 'is',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.get_words('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Titanic is my favorite movie.', 'The leading actor is good.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.get_sentences('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "`Dataset` contains samples and provides efficient and handy operation interfaces for samples. `Dataset` supports loading, verification, and saving data in JSON or CSV format for various NLP tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from textflint.input.dataset import Dataset\n",
    "\n",
    "# define your csv/json file path\n",
    "CSV_DATA_PATH = ''\n",
    "JSON_DATA_PATH = ''\n",
    "\n",
    "\n",
    "data1 = Dataset(task='SA')\n",
    "data2 = Dataset(task='SA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CSV_DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1n/dnn2n2j91bxgh4lj582p_j0m0000gn/T/ipykernel_73299/3792988084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data samples with load_csv or load_json function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSON_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CSV_DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# load data samples with load_csv or load_json function\n",
    "data1.load_csv(CSV_DATA_PATH, headers=['y', 'x'])\n",
    "data2.load_json(JSON_DATA_PATH)\n",
    "print(len(data1))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mTextFlint\u001b[0m: Save samples to /home/zxp/textrobustness/test/data/tmp/mini.csv!\n",
      "\u001b[34;1mTextFlint\u001b[0m: Save samples to /home/zxp/textrobustness/test/data/tmp/mini.json!\n"
     ]
    }
   ],
   "source": [
    "# save data samples with save_csv and save_json function\n",
    "import os\n",
    "data1.save_json(TEST_CSV_DATA_PATH)\n",
    "data2.save_csv(TEST_JSON_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
